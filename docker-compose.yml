version: "3.9"

services:
  biblioai:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: biblioai
    ports:
      - "3000:3000"  # Frontend
      - "3001:3001"  # Backend API
    environment:
      - NODE_ENV=production
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - PERPLEXITY_API_KEY=${PERPLEXITY_API_KEY:-}
      - SEMANTIC_SCHOLAR_API_KEY=${SEMANTIC_SCHOLAR_API_KEY:-}
      - PORT=3001
      - HOST=0.0.0.0
      - MAX_FILE_SIZE=10485760
    volumes:
      - extraction-results:/app/extraction-results
      - master-references:/app/master-references
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

volumes:
  extraction-results:
    driver: local
  master-references:
    driver: local

networks:
  default:
    name: biblioai-network
